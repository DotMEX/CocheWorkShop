#!/usr/bin/env python
import sys
import rospy
import cv2_to_imgmsg	#para open cv
import numpy as np
from sensor_msgs.msg import Image  #de aqui viene el tipo de dato Imagen
from geometry_msgs.msg import Pose
from cv_bridge import CvBridge, CvBridgeError
import math
import tf  #para transformaciones

class image_converter:

  def __init__(self):
    self.image_pub_gray = rospy.Publisher("/camera_pose/gray_img",Image, queue_size=1)
    self.image_pub_bi = rospy.Publisher("/camera_pose/bin_img",Image, queue_size=1)

    self.bridge = CvBridge()
    self.image_sub = rospy.Subscriber("/app/camera/rgb/image_raw",Image,self.callback, queue_size=1)


  def callback(self,data):
    try:
      cv_image = self.bridge.imgmsg_to_cv2(data, "bgr8")  #imgmsg_to_cv2 es la funcion para convertir la imagen
    except CvBridgeError as e:
      print(e)


    #make it gray
    gray=cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)

    try:
      self.image_pub_gray.publish(self.bridge.cv2_to_imgmsg(gray, "mono8"))   #se convierte de nuevo en el tipo de dato stdmsgs para mandarlo por el publicador en grises
    except CvBridgeError as e:
      print(e)

    #bi_gray
    bi_gray_max = 255
    bi_gray_min = 245
    ret,bw_img=cv2.threshold(gray, bi_gray_min, bi_gray_max, cv2.THRESH_BINARY);

    try:
      self.image_pub_bi.publish(self.bridge.cv2_to_imgmsg(bw_img, "mono8"))#se convierte de nuevo en el tipo de dato stdmsgs para mandarlo por el publicador en binario
    except CvBridgeError as e:
      print(e)

    ##Getting the points from image##
    image_points = np.zeros((6,2));

    for i in range (0,150):
        for j in range(0,320):
                  if (bw_img[i,j] >= 200):
                      image_points[0,0]=j
                      image_points[0,1]=i



    for i in range (150,300):
        for j in range (0,320):
               if (bw_img[i,j] >= 200):
                      image_points[1,0]=j
                      image_points[1,1]=i



    for i in range(300,480):
       for j in range(0,320):
                 if (bw_img[i,j] >= 200):
                      image_points[2,0]=j
                      image_points[2,1]=i



    for i in range(0,150):
       for j in range(320,640):
                 if (bw_img[i,j] >= 200):
                      image_points[3,0]=j
                      image_points[3,1]=i



    for i in range(150,300):
        for j in range(320,640):
                  if (bw_img[i,j] >= 200):
                      image_points[4,0]=j
                      image_points[4,1]=i


    for i in range (300,480):
        for j in range(320,640):
               if (bw_img[i,j] >= 200):
                      image_points[5,0]=j
                      image_points[5,1]=i


    print 'points: \n', image_points
    world_points=np.array([[0,80,0],[0,40,0],[0,0,0],[28,80,0],[28,40,0],[28,0,0]],np.float32) #coordenadas mundo de los puntos blancos en la imagen
    print 'w_points: \n', world_points
    intrinsics = np.array([[614.1699, 0, 329.9491], [0, 614.9002, 237.2788], [ 0, 0, 1]], np.float32) #datos de la camara inherentes
    distCoeffs = np.array([0.1115,-0.1089,0,0],np.float32) #coeficientes de distorcion de la camara
    rvec = np.zeros((3,1))
    tvec = np.zeros((3,1))
    cv2.solvePnP(world_points, image_points, intrinsics, distCoeffs, rvec, tvec); #Dar un vector de rotacion y de traslacion, pide puntos en coordenadas mundo, coordenadas encontradas en el mundo, parametros de la camara y parametros de distorcion de la camara, la salida son rvec, tvec
    print 'rvec \n' , rvec
    print 'tvec \n' , tvec
    rmat = cv2.Rodrigues(rvec)[0]  #Da como resultado una matriz de rotacion, es la transformación de la cámara hacia el mundo
    print 'rmat \n' , rmat
    inv_rmat = rmat.transpose()  #Inversa de la matriz
    print 'inv_rmat \n' , inv_rmat
    inv_rmat_ = np.negative(inv_rmat)
    inv_tvec = inv_rmat_.dot(tvec) #producto punto
    print 'inv_tvec \n' , inv_tvec
    sy = math.sqrt(rmat[0,0] * rmat[0,0] +  rmat[1,0] * rmat[1,0]); #Funcion para obtener los angulos con respecto al eje x, eje y, & eje z.
    singular = sy < 1e-6; # If
    if (~singular):
         x = math.atan2(-rmat[2,1] , rmat[2,2]);
         y = math.atan2(-rmat[2,0], sy);
         z = math.atan2(rmat[1,0], rmat[0,0]);
    else:
         x = math.atan2(-rmat[1,2], rmat[1,1]);
         y = math.atan2(-rmat[2,0], sy);
         z = 0;
    print 'x,y,z', x,y,z

    br = tf.TransformBroadcaster()   #
    br.sendTransform((inv_tvec[0]/100, inv_tvec[1]/100, inv_tvec[2]/100),
                     tf.transformations.quaternion_from_euler(x, y, z), #la transformacion necesita un cuaternion, transforma los angulos de euler a un cuaternion
                     rospy.Time(0), #etiqueta de tiempo, trae la ultima transformacion
                     "camera", #marco referencial de la camara
                     "world") #marco referencial del mundo

    
def main(args):
  rospy.init_node('camera_pose', anonymous=True)
  ic = image_converter()

  try:
    rospy.spin()
  except KeyboardInterrupt:
    print("Shutting down")

if __name__ == '__main__':
main(sys.argv)
